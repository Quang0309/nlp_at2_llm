{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2d9a2bd",
   "metadata": {},
   "source": [
    "### Load data from pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c47ccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time  # Import time to measure performance\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71519443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_and_split(pdf_directory):\n",
    "    all_pdf_docs = []\n",
    "    print(\"Loading documents...\")\n",
    "    for filename in os.listdir(pdf_directory):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(pdf_directory, filename)\n",
    "            try:\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                # .load() returns a list of Document objects, one for each page\n",
    "                docs_for_file = loader.load()\n",
    "                all_pdf_docs.extend(docs_for_file)\n",
    "                print(f\"Loaded {len(docs_for_file)} pages from {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "    return all_pdf_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b1536b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Loaded 114 pages from ANLP Session2_Week2_After Session-1.pdf\n",
      "Loaded 118 pages from ANLP Session3_Week4_After session-2.pdf\n",
      "Loaded 83 pages from ANLP Session1_Week1_Before Session-1.pdf\n",
      "Loaded 190 pages from ANLP Session4_Week5_After Session.pdf\n",
      "Loaded 27 pages from Extended topic - Text summarization slides.pdf\n"
     ]
    }
   ],
   "source": [
    "all_docs = []\n",
    "nlp_doc = load_pdf_and_split(\"dataset/nlp\")\n",
    "all_docs.extend(nlp_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a867e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=200\n",
    ")\n",
    "splits = text_splitter.split_documents(all_docs)\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf45a65",
   "metadata": {},
   "source": [
    "### Train LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bebe38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import MultiQueryRetriever\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8f613fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = (\n",
    "    \"You are a query rephrasing assistant. Your ONLY task is to rephrase a follow-up question into a standalone question. \"\n",
    "    \"Use the following chat history and user question to formulate the standalone question. \"\n",
    "    \"The standalone question MUST be understandable without the chat history. \"\n",
    "    \"If the user question is ALREADY a standalone question, you MUST return it without any changes. \"\n",
    "    \"Do NOT answer the question. Only provide the rephrased question.\"\n",
    "    \"\\n\\n\"\n",
    "    \"<chat_history>\"\n",
    "    \"{chat_history}\"\n",
    "    \"</chat_history>\"\n",
    "    \"\\n\\n\"\n",
    "    \"<user_question>\"\n",
    "    \"{input}\"\n",
    "    \"</user_question>\"\n",
    "    \"\\n\\n\"\n",
    "    \"Standalone question:\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", contextualize_q_system_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    ")\n",
    "\n",
    "qa_system_prompt = (\n",
    "    \"You are a specialized assistant for answering questions based ONLY on the provided documents. \"\n",
    "    \"The provided documents are excerpts from university course materials, including lecture slides, notes, assognments. \"\n",
    "    \"You are a helpful AI tutor for university of technology sydney students\"\n",
    "    \"Your task is to use the following pieces of retrieved context to answer the user's question. \"\n",
    "    \"Follow these rules STRICTLY:\\n\"\n",
    "    \"1. You MUST ONLY use the information present in the context provided below. DO NOT use any of your internal knowledge.\\n\"\n",
    "    \"2. If the context does not contain the answer to the question, you MUST respond with the exact phrase: 'The provided documents do not contain enough information to answer this question.'\\n\"\n",
    "    \"3. Do not add any extra information, explanations, or apologies. Just provide the answer from the context or the 'I don't know' phrase.\\n\\n\"\n",
    "    \"3. If the users greet you, simple greet back and dont mention anything else.\\n\\n\"\n",
    "\n",
    "    \"----------------\\n\"\n",
    "    \"CONTEXT:\\n\"\n",
    "    \"{context}\\n\"\n",
    "    \"----------------\"\n",
    ")\n",
    "\n",
    "# The qa_prompt creation remains the same\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed2e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "# This chain is responsible for retrieving relevant documents from the vector store.\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "        retriever=vectorstore.as_retriever(), llm=llm\n",
    "    )\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "        llm, retriever, contextualize_q_prompt\n",
    "    )\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aadd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "chat_history = []\n",
    "def ask_RAG(question):\n",
    "    # --- 5. Ask a Question ---\n",
    "\n",
    "    print(f\"\\nAsking question: {question}\")\n",
    "    response = retrieval_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "\n",
    "    answer = response[\"answer\"]\n",
    "    source_documents = response[\"context\"]\n",
    "\n",
    "    # Print the final answer\n",
    "    print(\"\\n--- Answer ---\")\n",
    "    print(answer)\n",
    "\n",
    "    # Append the user's message and the bot's response to the history\n",
    "    chat_history.append(HumanMessage(content=question))\n",
    "    chat_history.append(AIMessage(content=answer))\n",
    "\n",
    "    # Process and display the sources\n",
    "    if source_documents:\n",
    "        print(\"\\n--- Sources ---\")\n",
    "        # Use a set to store unique sources to avoid duplicates\n",
    "        unique_sources = set()\n",
    "        for doc in source_documents:\n",
    "            # doc.metadata is a dictionary, e.g., {'source': 'path/file.pdf', 'page': 0}\n",
    "            source_file = os.path.basename(doc.metadata['source']) # Get just the filename\n",
    "            page_number = doc.metadata['page'] + 1 # Add 1 because pages are 0-indexed\n",
    "            unique_sources.add(f\"File: {source_file}, Page: {page_number}\")\n",
    "    \n",
    "        for source in sorted(list(unique_sources)):\n",
    "            print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d82550c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_LLM(question):\n",
    "    ask_RAG(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b0268575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Asking question: Tell me what I will learn I this ANLP subject?\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['Here are three different versions of the original question, each with a unique perspective:', 'Tell me about the key takeaways and concepts that students typically explore in an Artificial Neural Networks for Language Processing (ANLP) course.', 'What skills and knowledge can I expect to gain from studying ANLP, and how might these insights be applied to real-world problems?', 'Can you provide me with an overview of the major topics and themes covered in an ANLP subject, including any relevant case studies or examples that illustrate key concepts?']\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "--- Answer ---\n",
      "According to the context provided, you will learn the following in this ANLP subject:\n",
      "\n",
      "1. Machine learning:\n",
      "   • Classification algorithms\n",
      "   • Sentiment Analysis\n",
      "   Neural networks and deep learning\n",
      "2. NLU (Natural Language Understanding) and NLG (Natural Language Generation)\n",
      "3. Large language models (LLMs)\n",
      "4. LLM deployment\n",
      "5. NLP applications for social good and NLP ethics\n",
      "\n",
      "Tutorial: NLP Basics (1)\n",
      "• Defining text as inputs\n",
      "• Displaying readable text\n",
      "• Tokenization\n",
      "• POS tagging\n",
      "• Named entity recognition\n",
      "• Dependency trees\n",
      "\n",
      "--- Sources ---\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 13\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 23\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 33\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 34\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 38\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 39\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 63\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 80\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 4\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 56\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 69\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 101\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 24\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 97\n"
     ]
    }
   ],
   "source": [
    "ask_LLM(\"Tell me what I will learn I this ANLP subject?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9fe2ab3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Asking question: Can you elaborate more on the topics you meantion?\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['Here are three alternative versions of the user question:', 'What are the key takeaways or insights related to specific topics that I should explore further?', 'Are there any specific themes, concepts, or ideas within topic areas that require more in-depth analysis or investigation?', 'Can you provide me with summaries or overviews of particular aspects of topics mentioned, such as main findings, supporting evidence, or relevant context?', 'What are the most significant connections or relationships between specific topics or their related aspects that I should be aware of or explore further?']\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "--- Answer ---\n",
      "The provided documents do not contain enough information to elaborate on the specific topics mentioned. The context only provides an overview of the ANLP subject and mentions various topics, but does not provide a detailed explanation of what will be covered in each topic.\n",
      "\n",
      "--- Sources ---\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 80\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 13\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 16\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 26\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 55\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 56\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 65\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 67\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 68\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 79\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 101\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 105\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 122\n",
      "File: Extended topic - Text summarization slides.pdf, Page: 1\n",
      "File: Extended topic - Text summarization slides.pdf, Page: 12\n",
      "File: Extended topic - Text summarization slides.pdf, Page: 16\n",
      "File: Extended topic - Text summarization slides.pdf, Page: 4\n"
     ]
    }
   ],
   "source": [
    "ask_LLM(\"Can you elaborate more on the topics you meantion?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4ec2d0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Asking question: What is Natural Language Processing (NLP)?\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['Here are three different versions of the user question:', 'What is Natural Language Processing (NLP)?', 'How do humans communicate with machines using natural language?', 'What is the field that enables computers to understand, interpret, and generate human-like text?', 'These alternative questions can help retrieve relevant documents from a vector database by providing multiple perspectives on the original question. By asking different questions, we can cover different aspects of NLP, such as its definition, functionality, or applications, which may not be captured by a single distance-based search query.']\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "--- Answer ---\n",
      "According to the provided documents, Natural Language Processing (NLP) is defined as:\n",
      "\n",
      "\"Natural Language Processing (NLP) is a sub-field of artificial intelligence that helps computers understand, interpret and manipulate human language.\"\n",
      "\n",
      "\"It's an interdisciplinary subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.\"\n",
      "\n",
      "--- Sources ---\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 14\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 26\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 27\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 28\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 38\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 17\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 36\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 101\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 105\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 11\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 31\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 37\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 5\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 19\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 25\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 35\n"
     ]
    }
   ],
   "source": [
    "ask_LLM(\"What is Natural Language Processing (NLP)?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "50a4bc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Asking question: What you will learn in ANLP?\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['Here are three different versions of the original question:', 'What topics or concepts will I gain knowledge about through studying ANLP?', 'What are the key takeaways and skills that someone learns when they study ANLP?', 'What are some examples of practical applications or new ideas that one can expect to learn from ANLP training?', 'These alternative questions aim to capture different aspects of the original question, such as focusing on the types of knowledge gained, the key takeaways, and the practical applications. This can help retrieve relevant documents from a vector database by providing multiple angles to search for related information.']\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "--- Answer ---\n",
      "According to the provided documents, in the ANLP subject, you will learn:\n",
      "\n",
      "\"Foundations of NLP (core concepts)\n",
      "• What is NLP, and why is it distinctive?\n",
      "• Basics of dissecting language using Python\n",
      "NLP for text analysis and reporting\n",
      "• Named entity recognition, Keywords and phrases, Lengths and frequencies\n",
      "• Pre-processing\n",
      "• Text visualisations\n",
      "• Storytelling for text data\n",
      "Topic modelling \n",
      "Clustering\"\n",
      "\n",
      "Note that this is not an exhaustive list, but rather a summary of the topics mentioned in the provided documents.\n",
      "\n",
      "--- Sources ---\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 13\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 16\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 23\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 33\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 63\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 8\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 80\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 4\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 67\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 118\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 22\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 32\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 15\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 16\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 24\n",
      "File: Extended topic - Text summarization slides.pdf, Page: 15\n",
      "File: Extended topic - Text summarization slides.pdf, Page: 23\n"
     ]
    }
   ],
   "source": [
    "ask_LLM(\"What you will learn in ANLP?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "507801fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Asking question: How to cook an egg\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['Here are three different versions of the original question:', 'How to cook an egg', \"What's a simple recipe for cooking eggs?\", 'Instructions for preparing boiled, fried, or scrambled eggs', 'These alternative questions can help retrieve relevant documents from a vector database by providing multiple perspectives on the original query. This approach can overcome some limitations of distance-based similarity search, such as:', '* Different wording or phrasing: The alternative questions use slightly different language to query the same topic.', '* Broader or narrower focus: Some alternative questions may broaden the scope (e.g., \"simple recipe\") while others narrow it down (e.g., \"boiled, fried, or scrambled eggs\").', '* Contextual variations: The alternative questions can be used in different contexts, such as cooking for a specific number of people, considering dietary restrictions, or exploring cultural traditions.', 'By providing these multiple perspectives on the original question, you can increase the chances of retrieving relevant documents from the vector database and provide more comprehensive search results.']\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "--- Answer ---\n",
      "The provided documents do not contain information on how to cook an egg. The context only provides materials related to Natural Language Processing (NLP) and does not include cooking instructions. If you're looking for a recipe, I suggest searching online or consulting a cookbook!\n",
      "\n",
      "--- Sources ---\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 55\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 8\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 100\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 102\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 21\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 24\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 25\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 35\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 4\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 46\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 67\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 68\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 118\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 41\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 85\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 86\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 90\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 15\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 16\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 170\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 18\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 19\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 24\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 32\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 60\n",
      "File: Extended topic - Text summarization slides.pdf, Page: 12\n",
      "File: Extended topic - Text summarization slides.pdf, Page: 23\n"
     ]
    }
   ],
   "source": [
    "ask_LLM(\"How to cook an egg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "391cbc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Asking question: tell me about Long short-term memory in very detail\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['Here are three different versions of the original question, each with a unique perspective:', 'Tell me about the architecture and key components of Long Short-Term Memory (LSTM) neural networks.', 'What are the advantages and limitations of using LSTMs for sequential data processing, such as natural language processing or time series forecasting?', 'Can you provide an in-depth explanation of how LSTMs differ from traditional Recurrent Neural Networks (RNNs), including their cell state mechanism and forget gate function?']\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "--- Answer ---\n",
      "According to the provided documents, here is the information on Long Short-Term Memory (LSTM):\n",
      "\n",
      "\"LSTM:\n",
      "VanillaRNN:\n",
      "\n",
      "* LSTM has additional gates!\n",
      "Long Short Term Memory (LSTM)\n",
      "- Extended topic\n",
      "\"\n",
      "\n",
      "This is a brief mention of LSTMs, but not a detailed explanation. However, based on this context, we can infer that LSTMs are a type of Recurrent Neural Network (RNN) that have added gates to help the network learn and maintain long-term dependencies in sequences.\n",
      "\n",
      "In more detail, an LSTM typically consists of three types of gates:\n",
      "\n",
      "1. **Input Gate** (also known as the \"write\" gate): This gate determines what new information is allowed into the cell state.\n",
      "2. **Output Gate** (also known as the \"read\" gate): This gate determines what information from the cell state should be outputted at each time step.\n",
      "3. **Forget Gate**: This gate decides which information to forget, essentially allowing the network to selectively \"forget\" certain parts of the sequence.\n",
      "\n",
      "These gates are used in combination with the cell state and hidden state to learn complex patterns in sequences. The exact mechanism of how LSTMs work is more complex and involves calculations such as sigmoidal activation functions, tanh functions, and element-wise multiplication.\n",
      "\n",
      "It's worth noting that this context does not provide a detailed explanation of LSTMs, but rather mentions it as an \"Extended topic\".\n",
      "\n",
      "--- Sources ---\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 39\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 4\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 101\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 43\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 97\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 155\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 156\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 161\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 167\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 168\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 176\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 183\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 49\n"
     ]
    }
   ],
   "source": [
    "ask_LLM(\"tell me about Long short-term memory in very detail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b1a02a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Asking question: Hi, it is nice to meet you\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['Here are three alternative versions of the original user question:', 'What information do you need assistance with?', \"I'm an AI designed to provide helpful responses. What's on your mind? How can I assist you?\", 'Seeking accurate and reliable information, what topic would you like me to address?', 'These alternative questions aim to capture the essence of the original query while providing different perspectives that might help retrieve relevant documents from a vector database.']\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "\n",
      "--- Answer ---\n",
      "Nice to meet you too! It's great to chat with you. I'm here to help answer your questions based on the provided documents. What's on your mind?\n",
      "\n",
      "--- Sources ---\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 22\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 68\n",
      "File: ANLP Session1_Week1_Before Session-1.pdf, Page: 82\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 26\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 65\n",
      "File: ANLP Session2_Week2_After Session-1.pdf, Page: 67\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 101\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 105\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 11\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 66\n",
      "File: ANLP Session3_Week4_After session-2.pdf, Page: 86\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 122\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 189\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 190\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 24\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 35\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 40\n",
      "File: ANLP Session4_Week5_After Session.pdf, Page: 9\n",
      "File: Extended topic - Text summarization slides.pdf, Page: 15\n"
     ]
    }
   ],
   "source": [
    "ask_LLM(\"Hi, it is nice to meet you\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d318b66",
   "metadata": {},
   "source": [
    "### Others Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f895c341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index from 'vector_store'...\n",
      "Found 555 chunks in the vector store.\n",
      "\n",
      "--- Unique PDF files found in the index ---\n",
      "- ANLP Session1_Week1_Before Session-1.pdf\n",
      "- ANLP Session2_Week2_After Session-1.pdf\n",
      "- ANLP Session3_Week4_After session-2.pdf\n",
      "- ANLP Session4_Week5_After Session.pdf\n",
      "- Extended topic - Text summarization slides.pdf\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "def inspect_index(index_path):\n",
    "    # We still need the embedding function to load the index\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    \n",
    "    if not os.path.exists(index_path):\n",
    "        print(f\"Error: Index path '{index_path}' not found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading index from '{index_path}'...\")\n",
    "    try:\n",
    "        vectorstore = FAISS.load_local(\n",
    "            index_path, \n",
    "            embeddings, \n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load index: {e}\")\n",
    "        return\n",
    "\n",
    "    # The docstore contains the mapping from index ID to the actual Document\n",
    "    if not hasattr(vectorstore, 'docstore') or not hasattr(vectorstore.docstore, '_dict'):\n",
    "        print(\"Could not find a valid docstore in the index.\")\n",
    "        return\n",
    "        \n",
    "    doc_dict = vectorstore.docstore._dict\n",
    "    print(f\"Found {len(doc_dict)} chunks in the vector store.\")\n",
    "    \n",
    "    # Use a set to find all unique source PDF files\n",
    "    unique_sources = set()\n",
    "    for doc_id, document in doc_dict.items():\n",
    "        if hasattr(document, 'metadata') and 'source' in document.metadata:\n",
    "            unique_sources.add(document.metadata['source'])\n",
    "            \n",
    "    print(\"\\n--- Unique PDF files found in the index ---\")\n",
    "    if not unique_sources:\n",
    "        print(\"No source files found in the metadata.\")\n",
    "    else:\n",
    "        for source in sorted(list(unique_sources)):\n",
    "            print(f\"- {os.path.basename(source)}\")\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inspect_index(\"vector_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a01db12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing query: 'What was in the lecture for week 1?' ---\n",
      "\n",
      "Retriever found 3 documents:\n",
      "  Result 1: From 'ANLP Session2_Week2_After Session-1.pdf', Page 8\n",
      "  Result 2: From 'ANLP Session1_Week1_Before Session-1.pdf', Page 81\n",
      "  Result 3: From 'ANLP Session1_Week1_Before Session-1.pdf', Page 80\n",
      "----------------------------------\n",
      "\n",
      "--- Testing query: 'What is Natural Language Processing (NLP)?' ---\n",
      "\n",
      "Retriever found 3 documents:\n",
      "  Result 1: From 'ANLP Session1_Week1_Before Session-1.pdf', Page 27\n",
      "  Result 2: From 'ANLP Session3_Week4_After session-2.pdf', Page 5\n",
      "  Result 3: From 'ANLP Session1_Week1_Before Session-1.pdf', Page 26\n",
      "----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test_retriever.py\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "FAISS_INDEX_PATH = \"vector_store\"\n",
    "\n",
    "def test_retrieval(index_path, query):\n",
    "    print(f\"--- Testing query: '{query}' ---\")\n",
    "    \n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    \n",
    "    if not os.path.exists(index_path):\n",
    "        print(\"Index not found. Please run your main script first.\")\n",
    "        return\n",
    "        \n",
    "    vectorstore = FAISS.load_local(\n",
    "        index_path, \n",
    "        embeddings, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    \n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3}) # Get top 3 results\n",
    "    \n",
    "    # Use the retriever directly to find relevant documents\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    \n",
    "    if not retrieved_docs:\n",
    "        print(\"Retriever found NO documents.\")\n",
    "        return\n",
    "        \n",
    "    print(f\"\\nRetriever found {len(retrieved_docs)} documents:\")\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        source_file = os.path.basename(doc.metadata.get('source', 'Unknown'))\n",
    "        page_number = doc.metadata.get('page', -1) + 1\n",
    "        print(f\"  Result {i+1}: From '{source_file}', Page {page_number}\")\n",
    "        # print(f\"    Content: {doc.page_content[:200]}...\") # Uncomment to see content\n",
    "    print(\"----------------------------------\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Query 1: This will probably fail to find the week 1 doc\n",
    "    test_retrieval(FAISS_INDEX_PATH, \"What was in the lecture for week 1?\")\n",
    "    \n",
    "    # Query 2: Find a keyword that you KNOW is inside lecture_week_1.pdf\n",
    "    # For example, if week 1 was about \"neural networks\", try that.\n",
    "    # Replace \"keyword from week 1 pdf\" with a real keyword.\n",
    "    test_retrieval(FAISS_INDEX_PATH, \"What is Natural Language Processing (NLP)?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "07a04512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing MultiQuery for: 'What is Natural Language Processing (NLP)?' ---\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['Here are three different versions of the original question:', 'What is Natural Language Processing NLP?', 'What does Natural Language Processing entail, and how does it differ from other areas of artificial intelligence?', 'What can you tell me about the field of Natural Language Processing, its applications, and its relationship to human language comprehension?', 'These alternative questions aim to capture different nuances and perspectives on the original question, which can help retrieve relevant documents that may not be immediately retrieved by a distance-based similarity search.']\n",
      "\n",
      "MultiQuery retriever found 14 documents.\n",
      "  - Source: ANLP Session4_Week5_After Session.pdf\n",
      "  - Source: ANLP Session4_Week5_After Session.pdf\n",
      "  - Source: ANLP Session2_Week2_After Session-1.pdf\n",
      "  - Source: ANLP Session3_Week4_After session-2.pdf\n",
      "  - Source: ANLP Session1_Week1_Before Session-1.pdf\n",
      "  - Source: ANLP Session3_Week4_After session-2.pdf\n",
      "  - Source: ANLP Session3_Week4_After session-2.pdf\n",
      "  - Source: ANLP Session1_Week1_Before Session-1.pdf\n",
      "  - Source: ANLP Session1_Week1_Before Session-1.pdf\n",
      "  - Source: ANLP Session1_Week1_Before Session-1.pdf\n",
      "  - Source: ANLP Session2_Week2_After Session-1.pdf\n",
      "  - Source: Extended topic - Text summarization slides.pdf\n",
      "  - Source: ANLP Session2_Week2_After Session-1.pdf\n",
      "  - Source: ANLP Session4_Week5_After Session.pdf\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Set up logging to see the generated queries\n",
    "#logging.basicConfig()\n",
    "#logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
    "\n",
    "FAISS_INDEX_PATH = \"vector_store\"\n",
    "\n",
    "def test_multiquery(index_path, query):\n",
    "    print(f\"--- Testing MultiQuery for: '{query}' ---\")\n",
    "    \n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    vectorstore = FAISS.load_local(\n",
    "        index_path, embeddings, allow_dangerous_deserialization=True\n",
    "    )\n",
    "    llm = ChatOllama(model=\"llama3\")\n",
    "    \n",
    "    # This will automatically log the generated queries to your console\n",
    "    retriever = MultiQueryRetriever.from_llm(\n",
    "        retriever=vectorstore.as_retriever(), llm=llm\n",
    "    )\n",
    "    \n",
    "    # We invoke it to trigger the query generation\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    \n",
    "    print(f\"\\nMultiQuery retriever found {len(retrieved_docs)} documents.\")\n",
    "    for doc in retrieved_docs:\n",
    "        print(f\"  - Source: {os.path.basename(doc.metadata['source'])}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unique_query = \"What is Natural Language Processing (NLP)?\"\n",
    "    test_multiquery(FAISS_INDEX_PATH, unique_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "61be1ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Definitive Retrieval Test ---\n",
      "Initializing the embedding model for the query...\n",
      "Loading vector store from 'vector_store'...\n",
      "\n",
      "Performing direct similarity search for: 'What is Natural Language Processing (NLP)?'\n",
      "\n",
      "--- Search Results ---\n",
      "  - Found source: ANLP Session1_Week1_Before Session-1.pdf, Page: 27\n",
      "  - Found source: ANLP Session3_Week4_After session-2.pdf, Page: 5\n",
      "  - Found source: ANLP Session1_Week1_Before Session-1.pdf, Page: 26\n",
      "  - Found source: ANLP Session3_Week4_After session-2.pdf, Page: 37\n",
      "\n",
      "!!! TEST FAILED: The search returned documents, but not the correct ones.\n",
      "This strongly suggests an embedding mismatch.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import os\n",
    "\n",
    "FAISS_INDEX_PATH = \"vector_store\"\n",
    "\n",
    "def definitive_retrieval_test(index_path):\n",
    "    print(\"--- Running Definitive Retrieval Test ---\")\n",
    "    \n",
    "    # 1. This is the \"key\" maker in your current notebook\n",
    "    print(\"Initializing the embedding model for the query...\")\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    \n",
    "    # 2. This is the \"lock\" created by your other notebook\n",
    "    print(f\"Loading vector store from '{index_path}'...\")\n",
    "    if not os.path.exists(index_path):\n",
    "        print(\"ERROR: Index path not found. Cannot run test.\")\n",
    "        return\n",
    "        \n",
    "    vectorstore = FAISS.load_local(\n",
    "        index_path, \n",
    "        embeddings, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    \n",
    "    # 3. We now perform a direct search. This tests if the key fits the lock.\n",
    "    # Replace with a real keyword you know for a fact is in ONE of your documents.\n",
    "    specific_query = \"What is Natural Language Processing (NLP)?\"\n",
    "    print(f\"\\nPerforming direct similarity search for: '{specific_query}'\")\n",
    "    \n",
    "    # .similarity_search() is the most basic search function.\n",
    "    retrieved_docs = vectorstore.similarity_search(specific_query, k=4)\n",
    "    \n",
    "    if not retrieved_docs:\n",
    "        print(\"!!! TEST FAILED: The search returned ZERO documents.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Search Results ---\")\n",
    "    found_match = False\n",
    "    for doc in retrieved_docs:\n",
    "        source_file = os.path.basename(doc.metadata.get('source', 'Unknown'))\n",
    "        print(f\"  - Found source: {source_file}, Page: {doc.metadata.get('page', -1) + 1}\")\n",
    "        if \"your_document_name\" in source_file: # Check if it found the right file\n",
    "            found_match = True\n",
    "\n",
    "    if found_match:\n",
    "        print(\"\\nSUCCESS: The search found the correct document!\")\n",
    "    else:\n",
    "        print(\"\\n!!! TEST FAILED: The search returned documents, but not the correct ones.\")\n",
    "        print(\"This strongly suggests an embedding mismatch.\")\n",
    "\n",
    "# Run the test\n",
    "definitive_retrieval_test(FAISS_INDEX_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
